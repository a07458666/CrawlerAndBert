{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import io\n",
    "import time\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sleeptime(hore,min,sec):\n",
    "    return hore * 3600 + min * 60 + sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "200\n"
    }
   ],
   "source": [
    "url = \"https://www.dcard.tw/f\"\n",
    "headers = {'User-Agent':'Mozilla/5.0(Windows NT 10.0;Win64;x64)AppleWebKit / 537.36 Chrome / 70.0.3538.102 Safari / 537.36'} \n",
    "resp = requests.get(url, headers = headers)\n",
    "print(resp.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(resp.text, 'html.parser')\n",
    "dcard_title = soup.find_all('a', re.compile('sc-1v1d5rx-3 kPUUNB'))\n",
    "dcard_title_s = []\n",
    "for i, title in enumerate(dcard_title):\n",
    "    print(str(i) + \". \" + title.span.string)\n",
    "    dcard_title_s.append(title.span.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "PyTorch 版本： 1.3.1\n"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer\n",
    "from IPython.display import clear_output\n",
    "from transformers import BertForMaskedLM\n",
    "\n",
    "PRETRAINED_MODEL_NAME = \"bert-base-chinese\"  # 指定繁簡中文 BERT-BASE 預訓練模型\n",
    "\n",
    "# 取得此預訓練模型所使用的 tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(PRETRAINED_MODEL_NAME)\n",
    "\n",
    "clear_output()\n",
    "print(\"PyTorch 版本：\", torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "21128\n"
    }
   ],
   "source": [
    "vocab = tokenizer.vocab\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "list index out of range",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-61f365a67e13>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdcard_title_s\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_tokens_to_ids\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtokens\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'[MASK]'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "text = dcard_title_s[12]\n",
    "print(text)\n",
    "tokens = tokenizer.tokenize(text)\n",
    "ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "tokens[5] = '[MASK]'\n",
    "ids[5] = 103\n",
    "print(tokens[:20], '...')\n",
    "print(ids[:20], '...')\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_tensor = torch.tensor([ids])\n",
    "segments_tensors = torch.zeros_like(tokens_tensor)  # (1, seq_len)\n",
    "maskedLM_model = BertForMaskedLM.from_pretrained(PRETRAINED_MODEL_NAME)\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "maskedLM_model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = maskedLM_model(tokens_tensor, segments_tensors)\n",
    "    predictions = outputs[0]\n",
    "del maskedLM_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "輸入 tokens ： ['寵', '物', '真', '的', '有', '[MASK]', '情'] ...\n--------------------------------------------------\nTop 1 (21%)：['寵', '物', '真', '的', '有', '愛', '情'] ...\nTop 2 ( 8%)：['寵', '物', '真', '的', '有', '純', '情'] ...\nTop 3 ( 7%)：['寵', '物', '真', '的', '有', '色', '情'] ...\nTop 4 ( 4%)：['寵', '物', '真', '的', '有', '戀', '情'] ...\nTop 5 ( 4%)：['寵', '物', '真', '的', '有', '感', '情'] ...\n"
    }
   ],
   "source": [
    "# 將 [MASK] 位置的機率分佈取 top k 最有可能的 tokens 出來\n",
    "masked_index = 5\n",
    "k = 5\n",
    "probs, indices = torch.topk(torch.softmax(predictions[0, masked_index], -1), k)\n",
    "predicted_tokens = tokenizer.convert_ids_to_tokens(indices.tolist())\n",
    "\n",
    "# 顯示 top k 可能的字。一般我們就是取 top 1 當作預測值\n",
    "print(\"輸入 tokens ：\", tokens[:10], '...')\n",
    "print('-' * 50)\n",
    "for i, (t, p) in enumerate(zip(predicted_tokens, probs), 1):\n",
    "    tokens[masked_index] = t\n",
    "    print(\"Top {} ({:2}%)：{}\".format(i, int(p.item() * 100), tokens[:10]), '...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37464bitandysuvirtualenv3d81237157b54bc697c4b1ffd4417a26",
   "display_name": "Python 3.7.4 64-bit ('AndySu': virtualenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}