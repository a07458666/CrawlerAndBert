{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import io\n",
    "import time\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sleeptime(hore,min,sec):\n",
    "    return hore * 3600 + min * 60 + sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "200\n"
    }
   ],
   "source": [
    "url = \"https://www.dcard.tw/f\"\n",
    "headers = {'User-Agent':'Mozilla/5.0(Windows NT 10.0;Win64;x64)AppleWebKit / 537.36 Chrome / 70.0.3538.102 Safari / 537.36'} \n",
    "resp = requests.get(url, headers = headers)\n",
    "print(resp.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0. #åŠç†Ÿå¤§äººäº¤æœ‹å‹  Lulu é»ƒè·¯æ¢“èŒµï¼šæˆ‘çš„äººç”Ÿå°±æ˜¯ä¸€å€‹ã€Œè¶…å‰éƒ¨ç½²ã€\n1. åœ¨äº¤å‹è»Ÿé«”ä¸Šé‡åˆ°è¦ªå§â€¦â€¦ï¼Ÿ\n2. ç©¿è‘—æ¯”è¼ƒéœ²çš„è¡£æœçˆ­è­°\n3. æ™‚å°šç•Œéœ‡æ’¼å½ˆGUCCIå®£å¸ƒé€€å‡ºæ™‚è£é€±\n4. é«˜æ¸…ç„¡ç¢¼ğŸ˜ï¼ˆå…§æœ‰ç…§ç‰‡ï¼‰\n5. çµ‚æ–¼è¦‹åˆ°å¡å‹äº†~\n6. å¥³å®¿å¤–æœ‰äººè¶´åœ¨æ¬„æ†ä¸Šå·çœ‹\n7. å¹´è¼•çš„é›ï¼ˆï¼Ÿï¼Ÿï¼Ÿï¼Ÿï¼Ÿ\n8. èƒ¸éƒ¨ä¸‹æ“ å‡ºå·¨å‹ç²‰åˆº\n9. æ˜Ÿå·´å…‹ç¾äººé­šè©¦å–çµæœï¼Ÿï¼\n10. ç¾å’–çœŸçš„ç„¡æ‰€ä¸ç”¨å…¶æ¥µæ¬¸\n11. åªæœ‰æˆ‘è¦ºå¾—Miyeonç€æµ·è¶…æ­£å—\n12. ç•¶8ï¼‹9å…¶å¯¦çœŸçš„å¾ˆçˆ½\n13. é€™æ¨£æ‹’çµ•é‚„ä¸å¤ æ˜é¡¯å—\n14. æ±‚æ•‘ï½ï½èƒŒå¿ƒè£¡é¢å…§è¡£è¦æ€éº¼ç©¿\n15. å¥³å‹æ˜¯å…¨ä¸–ç•Œæœ€æ©Ÿæ°çš„ç”Ÿç‰©\n16. 8+9æœ€æ„›çš„é£Ÿç‰©\n17. #å°ä¸­#é»‘ç‰¹#ç¬¬ä¸€æ¬¡åšç¾ç”²åšåˆ°æ»¿æ‰‹å‚·ç—•\n18. åœ­è³¢å•Š~é€™14å¹´ä¾†è¾›è‹¦å•¦â˜ºï¸\n19. <0528*æ›´+æŠ±æ­‰,åŸæ„ç´”å±¬åˆ†äº«> ä¸€äº›è®€æ›¸å¸³çš„æ—¥å¸¸\n20. é–¨èœœè¦æˆ‘ä¸Ÿäº†æˆ‘çš„æ¯”åŸºå°¼\n21. å£“éºµåŒ…å¾ˆå¥‡æ€ªï¼Ÿ\n22. é—œæ–¼é†«ç”Ÿçš„å£é ­ç¦ª\n23. å–œæ­¡è­¦å¯Ÿåˆ¶æœçš„äººæ˜¯ä»€éº¼æ„Ÿè¦º\n24. ä½ˆç½®é¢¨æ ¼åˆ†äº«ï½œä¹¾æ·¨æœ¨è³ªèª¿ğŸ•°\n25. #æ›´ SEULGI X IRENE 6/15 MONSTER å‡ºé“\n26. ä¸å°å¿ƒçœ‹åˆ°ç”·å‹é›»è…¦è£¡çš„å¤§å¥¶å¦¹\n27. NetflixçœŸçš„å¾ˆé›·å—ï¼Ÿ\n28. æœ‹å¥‰å“¥ç­”æ‡‰ã€Œæµªå­å›é ­ã€ï¼Œåˆä½œå¤¥ä¼´ï¼šæ°¸é å¿˜ä¸äº†\n29. #åˆ†äº« ä¸‰å€‹æœˆéå¾Œæˆ‘çš„è‡‰å¹¾ä¹æ¢å¾©å•¦( Â´â–½` )ï¾‰\n"
    }
   ],
   "source": [
    "soup = BeautifulSoup(resp.text, 'html.parser')\n",
    "dcard_title = soup.find_all('a', re.compile('sc-1v1d5rx-3 kPUUNB'))\n",
    "dcard_title_s = []\n",
    "for i, title in enumerate(dcard_title):\n",
    "    print(str(i) + \". \" + title.span.string)\n",
    "    dcard_title_s.append(title.span.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "PyTorch ç‰ˆæœ¬ï¼š 1.3.1\n"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer\n",
    "from IPython.display import clear_output\n",
    "from transformers import BertForMaskedLM\n",
    "\n",
    "PRETRAINED_MODEL_NAME = \"bert-base-chinese\"  # æŒ‡å®šç¹ç°¡ä¸­æ–‡ BERT-BASE é è¨“ç·´æ¨¡å‹\n",
    "\n",
    "# å–å¾—æ­¤é è¨“ç·´æ¨¡å‹æ‰€ä½¿ç”¨çš„ tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(PRETRAINED_MODEL_NAME)\n",
    "\n",
    "clear_output()\n",
    "print(\"PyTorch ç‰ˆæœ¬ï¼š\", torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "21128\n"
    }
   ],
   "source": [
    "vocab = tokenizer.vocab\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "ç•¶8ï¼‹9å…¶å¯¦çœŸçš„å¾ˆçˆ½\n['ç•¶', '8', '##ï¼‹', '##9', 'å…¶', '[MASK]', 'çœŸ', 'çš„', 'å¾ˆ', 'çˆ½'] ...\n[4534, 129, 11267, 8160, 1071, 103, 4696, 4638, 2523, 4272] ...\n"
    }
   ],
   "source": [
    "text = dcard_title_s[12]\n",
    "print(text)\n",
    "tokens = tokenizer.tokenize(text)\n",
    "ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "tokens[5] = '[MASK]'\n",
    "ids[5] = 103\n",
    "print(tokens[:20], '...')\n",
    "print(ids[:20], '...')\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_tensor = torch.tensor([ids])\n",
    "segments_tensors = torch.zeros_like(tokens_tensor)  # (1, seq_len)\n",
    "maskedLM_model = BertForMaskedLM.from_pretrained(PRETRAINED_MODEL_NAME)\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "maskedLM_model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = maskedLM_model(tokens_tensor, segments_tensors)\n",
    "    predictions = outputs[0]\n",
    "del maskedLM_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "è¼¸å…¥ tokens ï¼š ['ç•¶', '8', '##ï¼‹', '##9', 'å…¶', '[MASK]', 'çœŸ', 'çš„', 'å¾ˆ', 'çˆ½'] ...\n--------------------------------------------------\nTop 1 (82%)ï¼š['ç•¶', '8', '##ï¼‹', '##9', 'å…¶', 'å¯¦', 'çœŸ', 'çš„', 'å¾ˆ', 'çˆ½'] ...\nTop 2 ( 5%)ï¼š['ç•¶', '8', '##ï¼‹', '##9', 'å…¶', 'å¾Œ', 'çœŸ', 'çš„', 'å¾ˆ', 'çˆ½'] ...\nTop 3 ( 3%)ï¼š['ç•¶', '8', '##ï¼‹', '##9', 'å…¶', 'ä¸­', 'çœŸ', 'çš„', 'å¾ˆ', 'çˆ½'] ...\nTop 4 ( 0%)ï¼š['ç•¶', '8', '##ï¼‹', '##9', 'å…¶', 'ä¸Š', 'çœŸ', 'çš„', 'å¾ˆ', 'çˆ½'] ...\nTop 5 ( 0%)ï¼š['ç•¶', '8', '##ï¼‹', '##9', 'å…¶', 'å', 'çœŸ', 'çš„', 'å¾ˆ', 'çˆ½'] ...\n"
    }
   ],
   "source": [
    "# å°‡ [MASK] ä½ç½®çš„æ©Ÿç‡åˆ†ä½ˆå– top k æœ€æœ‰å¯èƒ½çš„ tokens å‡ºä¾†\n",
    "masked_index = 5\n",
    "k = 5\n",
    "probs, indices = torch.topk(torch.softmax(predictions[0, masked_index], -1), k)\n",
    "predicted_tokens = tokenizer.convert_ids_to_tokens(indices.tolist())\n",
    "\n",
    "# é¡¯ç¤º top k å¯èƒ½çš„å­—ã€‚ä¸€èˆ¬æˆ‘å€‘å°±æ˜¯å– top 1 ç•¶ä½œé æ¸¬å€¼\n",
    "print(\"è¼¸å…¥ tokens ï¼š\", tokens[:10], '...')\n",
    "print('-' * 50)\n",
    "for i, (t, p) in enumerate(zip(predicted_tokens, probs), 1):\n",
    "    tokens[masked_index] = t\n",
    "    print(\"Top {} ({:2}%)ï¼š{}\".format(i, int(p.item() * 100), tokens[:10]), '...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37464bitandysuvirtualenv3d81237157b54bc697c4b1ffd4417a26",
   "display_name": "Python 3.7.4 64-bit ('AndySu': virtualenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}